{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beta Bank has had customers leaving and would like to retain its customers. Therefore, Beta Bank seeks to predict the likelihood of a customer leaving the bank soon. We will use data on clients’ past behavior and termination of contracts with the bank to build a model that can predict whether or not a client will leave based on client information. Our goal is to train a model with a minimum F1 score of 0.59."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Churn.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains 10000 records and 14 columns:\n",
    "\n",
    "Features\n",
    " - RowNumber — data string index\n",
    " - CustomerId — unique customer identifier\n",
    " - Surname — surname\n",
    " - CreditScore — credit score\n",
    " - Geography — country of residence\n",
    " - Gender — gender\n",
    " - Age — age\n",
    " - Tenure — period of maturation for a customer’s fixed deposit (years)\n",
    " - Balance — account balance\n",
    " - NumOfProducts — number of banking products used by the customer\n",
    " - HasCrCard — customer has a credit card\n",
    " - IsActiveMember — customer’s activeness\n",
    " - EstimatedSalary — estimated salary\n",
    "\n",
    "Target\n",
    " - Exited — сustomer has left (\"1\" = exited, \"0\" = remained)\n",
    " \n",
    "All of the variables are numeric except 'surname', 'geography' and 'gender'. These are object types. We will need the data to be in numeric form. Since 'surname' is unlikely to predict the target variable, we will drop this variable from the dataframe. However, 'geography' and 'gender' may help predict the target so we will encode these as numeric variables. We will convert all column names to lowercase to keep code clean. We will also convert floats to integers since some methods require integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [RowNumber, CustomerId, Surname, CreditScore, Geography, Gender, Age, Tenure, Balance, NumOfProducts, HasCrCard, IsActiveMember, EstimatedSalary, Exited]\n",
       "Index: []"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for duplicates\n",
    "\n",
    "duplicate = df[df.duplicated()]\n",
    "\n",
    "duplicate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicate rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing <a class=\"anchor\" id=\"section_1_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to Lowercase <a class=\"anchor\" id=\"section_1_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all column names to lowercase\n",
    "\n",
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values <a class=\"anchor\" id=\"section_1_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rownumber            0\n",
       "customerid           0\n",
       "surname              0\n",
       "creditscore          0\n",
       "geography            0\n",
       "gender               0\n",
       "age                  0\n",
       "tenure             909\n",
       "balance              0\n",
       "numofproducts        0\n",
       "hascrcard            0\n",
       "isactivemember       0\n",
       "estimatedsalary      0\n",
       "exited               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only variable with missing values is 'tenure'. It has 909 missing values, which is roughly 9% of the data. Let's check the value counts and a histogram to see the distribution of 'tenure' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     952\n",
       "2.0     950\n",
       "8.0     933\n",
       "3.0     928\n",
       "5.0     927\n",
       "7.0     925\n",
       "4.0     885\n",
       "9.0     882\n",
       "6.0     881\n",
       "10.0    446\n",
       "0.0     382\n",
       "Name: tenure, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking value counts of 'tenure'\n",
    "\n",
    "df['tenure'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting distribution of 'tenure'\n",
    "\n",
    "df['tenure'].hist(edgecolor='black', linewidth=1.2, figsize=(15,5))\n",
    "plt.xlabel('Tenure')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency of Tenure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in 'tenure' are pretty normally distributed overall. We would prefer not to lose 10% of the data, so let's replace missing values with the mean of the 'tenure' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rownumber          0\n",
       "customerid         0\n",
       "surname            0\n",
       "creditscore        0\n",
       "geography          0\n",
       "gender             0\n",
       "age                0\n",
       "tenure             0\n",
       "balance            0\n",
       "numofproducts      0\n",
       "hascrcard          0\n",
       "isactivemember     0\n",
       "estimatedsalary    0\n",
       "exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing missing values in 'tenure' with mean of 'tenure' values\n",
    "\n",
    "df['tenure'].fillna(value=df['tenure'].mean(), inplace=True)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Integers <a class=\"anchor\" id=\"section_1_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   rownumber        10000 non-null  int64 \n",
      " 1   customerid       10000 non-null  int64 \n",
      " 2   surname          10000 non-null  object\n",
      " 3   creditscore      10000 non-null  int64 \n",
      " 4   geography        10000 non-null  object\n",
      " 5   gender           10000 non-null  object\n",
      " 6   age              10000 non-null  int64 \n",
      " 7   tenure           10000 non-null  int32 \n",
      " 8   balance          10000 non-null  int32 \n",
      " 9   numofproducts    10000 non-null  int64 \n",
      " 10  hascrcard        10000 non-null  int64 \n",
      " 11  isactivemember   10000 non-null  int64 \n",
      " 12  estimatedsalary  10000 non-null  int32 \n",
      " 13  exited           10000 non-null  int64 \n",
      "dtypes: int32(3), int64(8), object(3)\n",
      "memory usage: 976.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Converting 'tenure', 'balance' and 'estimatedsalary' from float to integer types\n",
    "\n",
    "df['tenure'] = df['tenure'].astype(int)\n",
    "df['balance'] = df['balance'].astype(int)\n",
    "df['estimatedsalary'] = df['estimatedsalary'].astype(int)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Columns <a class=\"anchor\" id=\"section_1_1\"></a>\n",
    "\n",
    "The 'surname' variable will result in thousands of dummy variables that will stress the model. Since 'surname' is unlikely to predict the target variable, we will drop this variable from the dataframe. We will also drop 'rownumber' and 'customerid' since they do not provide any useful information and will confuse the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creditscore</th>\n",
       "      <th>geography</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      creditscore geography  gender  age  tenure  balance  numofproducts  \\\n",
       "0             619    France  Female   42       2        0              1   \n",
       "1             608     Spain  Female   41       1    83807              1   \n",
       "2             502    France  Female   42       8   159660              3   \n",
       "3             699    France  Female   39       1        0              2   \n",
       "4             850     Spain  Female   43       2   125510              1   \n",
       "...           ...       ...     ...  ...     ...      ...            ...   \n",
       "9995          771    France    Male   39       5        0              2   \n",
       "9996          516    France    Male   35      10    57369              1   \n",
       "9997          709    France  Female   36       7        0              1   \n",
       "9998          772   Germany    Male   42       3    75075              2   \n",
       "9999          792    France  Female   28       4   130142              1   \n",
       "\n",
       "      hascrcard  isactivemember  estimatedsalary  exited  \n",
       "0             1               1           101348       1  \n",
       "1             0               1           112542       0  \n",
       "2             1               0           113931       1  \n",
       "3             0               0            93826       0  \n",
       "4             1               1            79084       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0            96270       0  \n",
       "9996          1               1           101699       0  \n",
       "9997          0               1            42085       1  \n",
       "9998          1               0            92888       1  \n",
       "9999          1               0            38190       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping 'surname' column\n",
    "\n",
    "df = df.drop(['surname', 'rownumber', 'customerid'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Categorical Variables with OHE <a class=\"anchor\" id=\"section_1_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plan to initially use a LogisticRegression model so we need to convert the feature categorical variables into numerical variables using an encoder before training the model.\n",
    "\n",
    "However, 'geography' and 'gender' may help predict the target so we will encode these as numeric variables. These OHE variables have few categories and they are unlikely to be so predictive so we will use OHE encoding for the tree models as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many columns will be added by OHE of 'gender' and 'geography'. Let's check the unique values in 'geography'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Female', 'Male'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking unique values in 'gender'\n",
    "\n",
    "df['gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['France', 'Spain', 'Germany'], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking unique values in 'geography'\n",
    "\n",
    "df['geography'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 2 categories in 'gender' and 3 categories in the 'geography' variable so encoding will not add too many columns to our dataframe. We will drop the first column of each variable to avoid a dummy trap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creditscore</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "      <th>geography_Germany</th>\n",
       "      <th>geography_Spain</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      creditscore  age  tenure  balance  numofproducts  hascrcard  \\\n",
       "0             619   42       2        0              1          1   \n",
       "1             608   41       1    83807              1          0   \n",
       "2             502   42       8   159660              3          1   \n",
       "3             699   39       1        0              2          0   \n",
       "4             850   43       2   125510              1          1   \n",
       "...           ...  ...     ...      ...            ...        ...   \n",
       "9995          771   39       5        0              2          1   \n",
       "9996          516   35      10    57369              1          1   \n",
       "9997          709   36       7        0              1          0   \n",
       "9998          772   42       3    75075              2          1   \n",
       "9999          792   28       4   130142              1          1   \n",
       "\n",
       "      isactivemember  estimatedsalary  exited  geography_Germany  \\\n",
       "0                  1           101348       1                  0   \n",
       "1                  1           112542       0                  0   \n",
       "2                  0           113931       1                  0   \n",
       "3                  0            93826       0                  0   \n",
       "4                  1            79084       0                  0   \n",
       "...              ...              ...     ...                ...   \n",
       "9995               0            96270       0                  0   \n",
       "9996               1           101699       0                  0   \n",
       "9997               1            42085       1                  0   \n",
       "9998               0            92888       1                  1   \n",
       "9999               0            38190       0                  0   \n",
       "\n",
       "      geography_Spain  gender_Male  \n",
       "0                   0            0  \n",
       "1                   1            0  \n",
       "2                   0            0  \n",
       "3                   0            0  \n",
       "4                   1            0  \n",
       "...               ...          ...  \n",
       "9995                0            1  \n",
       "9996                0            1  \n",
       "9997                0            0  \n",
       "9998                0            1  \n",
       "9999                0            0  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding categorical variables\n",
    "\n",
    "df_ohe = pd.get_dummies(df, drop_first = True)\n",
    "df_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After encoding, our dataframe has 14 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign the Target Variable  <a class=\"anchor\" id=\"section_1_1\"></a>\n",
    "\n",
    "Our goal is to predict which customers will exit the bank based on the behavior of customers with similar features. We will assign 'exited' as our target variable and train our model to predict whether or not a customer exited the bank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 11)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# We will assign 'exited' as the target variable, the feature we need to predict, and the remaining attributes as the features.\n",
    " \n",
    "features = df_ohe.drop(['exited'], axis=1)\n",
    "target = df_ohe['exited']\n",
    " \n",
    "print(features.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Balance of Classes  <a class=\"anchor\" id=\"section_1_1\"></a>\n",
    "\n",
    "Before we train our model, we need to know the class distribution of 'exited'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.7963\n",
       "1    0.2037\n",
       "Name: exited, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking value counts of 'exited'\n",
    "\n",
    "df_ohe['exited'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an imbalance between the classes. 20% of customers exited and 80% did not. We will account for this imbalance later in the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Dataframe 3-Way <a class=\"anchor\" id=\"chapter1\"></a>\n",
    "\n",
    "First we will start with the source data and split it into three parts: training, validation, and test. This way, we can compare three models and use the test set for the final evaluation of the best model. We will leave as much data for the training as possible but make the sizes of the validation set and the test set equal. This will give us a source data split into a 3:1:1 ratio or  60% training, 20% validation, and 20% testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 11)\n",
      "(8000,)\n",
      "(2000, 11)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting data into 60% training dataset, 20% training dataset, 20% test dataset in two steps:\n",
    "# First, we split data into 80% training and 20% test\n",
    " \n",
    "df_train, df_test = train_test_split(df_ohe, test_size=0.20, random_state=12345)\n",
    " \n",
    "features_train = df_train.drop(['exited'], axis=1)\n",
    "target_train = df_train['exited']\n",
    "features_test = df_test.drop(['exited'], axis=1)\n",
    "target_test = df_test['exited']\n",
    " \n",
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "print(features_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 11)\n",
      "(6000,)\n",
      "(2000, 11)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "# Then, we split data using a 0.25% test size for the validation set, effectively creating a 60% training dataset and a 20% validation dataset\n",
    " \n",
    "df_train, df_valid = train_test_split(df_train, test_size=0.25, random_state=12345)\n",
    " \n",
    "features_train = df_train.drop(['exited'], axis=1)\n",
    "target_train = df_train['exited']\n",
    "features_valid = df_valid.drop(['exited'], axis=1)\n",
    "target_valid = df_valid['exited']\n",
    " \n",
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(target_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize the Data  <a class=\"anchor\" id=\"section_1_1\"></a>\n",
    "We need to scale the features so that features with higher values do not get unnecessary weighting during the model training. We will used standard scaler to standardize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the data\n",
    "\n",
    "numeric = ['creditscore', 'age', 'tenure', 'balance', 'numofproducts', 'estimatedsalary']\n",
    " \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric]) \n",
    "pd.options.mode.chained_assignment = None\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric]= scaler.transform(features_test[numeric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pilot Training <a class=\"anchor\" id=\"chapter1\"></a>\n",
    "\n",
    "We will initially train a model using LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=12345, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=12345, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=12345, solver='liblinear')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Developing a model with LogisticRegression\n",
    " \n",
    "model =  LogisticRegression(random_state=12345, solver='liblinear') \n",
    "model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model<a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.30131826741996237\n",
      "AUC-ROC score: 0.77053625784629\n"
     ]
    }
   ],
   "source": [
    "# Checking F1 score of the Logistic Regression Model\n",
    "\n",
    "predictions = model.predict(features_valid)\n",
    "print('F1:', f1_score(target_valid, predictions))\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC-ROC score:',auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Logistic Regression Model F1 score was 0.30, which is relatively low, and the AUC_ROC score was 0.77. This was likely due to the class imbalance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting Class Imbalance <a class=\"anchor\" id=\"chapter1\"></a>\n",
    "\n",
    "One of the ways to improve the accuracy of our model is to correct the class imbalance in our target variable by making the rare class weigh more.\n",
    "\n",
    "We will use various methods to adjust the class imbalance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.4772117962466488\n",
      "AUC-ROC score: 0.7726344300521841\n"
     ]
    }
   ],
   "source": [
    "# Using 'balanced' paramter to correct class imbalance\n",
    "\n",
    "model = LogisticRegression(random_state=12345, class_weight='balanced', solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('F1:', f1_score(target_valid, predicted_valid))\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC-ROC score:',auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a balanced parameter, the F1 score was 0.48, still low. The AUC_ROC was still 0.77."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling <a class=\"anchor\" id=\"chapter1\"></a>\n",
    "\n",
    "We will create a function for upsampling. The ratio of \"1\" to \"0\" in our sample is about 2:8 so we will need to repeat the \"1\" 4 times to correct the class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function for upsampling\n",
    "\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target_train[target_train == 0]\n",
    "    target_ones = target_train[target_train == 1]\n",
    " \n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    " \n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    " \n",
    "    return features_upsampled, target_upsampled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9657, 11)\n",
      "(9657,)\n"
     ]
    }
   ],
   "source": [
    "# Applying upsampling to our training set\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(\n",
    "    features_train, target_train, 4\n",
    ")\n",
    " \n",
    "print(features_upsampled.shape)\n",
    "print(target_upsampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.47585601404740996\n",
      "AUC-ROC score: 0.7726550938693635\n"
     ]
    }
   ],
   "source": [
    "# Retraining model using upsampling set\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', random_state=12345) \n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('F1:', f1_score(target_valid, predicted_valid))\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC-ROC score:',auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1 score of the LogisticRegression model after unsampling was 0.48 and the AUC_ROC was 0.77."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling <a class=\"anchor\" id=\"chapter1\"></a>\n",
    "\n",
    "We can also use downsampling to reduce the more common class in the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function for downsampling to reduct the class of \"0\" in the set.\n",
    "\n",
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    " \n",
    "    features_downsampled = np.concatenate([features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = np.concatenate([target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled, random_state=12345) \n",
    " \n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2414, 11)\n",
      "(2414,)\n"
     ]
    }
   ],
   "source": [
    "# Applying downsampling to our training set\n",
    "\n",
    "features_downsampled, target_downsampled = downsample(\n",
    "    features_train, target_train, 0.25\n",
    ")\n",
    " \n",
    "print(features_downsampled.shape)\n",
    "print(target_downsampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.4757709251101322\n",
      "AUC-ROC score: 0.7737979619118164\n"
     ]
    }
   ],
   "source": [
    "# Retraining model using downsampling set\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', random_state=12345) \n",
    "model.fit(features_downsampled, target_downsampled)\n",
    "\n",
    "predictions_down = model.predict(features_valid) \n",
    "print('F1:', f1_score(target_valid, predictions_down))\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC-ROC score:',auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1 score was 0.48 and the AUC_ROC was 0.77, after downsampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will train different models and compare the models to the LogisticRegression models to find the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop Different Models <a class=\"anchor\" id=\"chapter1\"></a>\n",
    "\n",
    "We trained a LogisticRegression model. To find the best model, we will also train a RandomForest Classifier model and a DecisionTreeClassifier model.\n",
    " \n",
    "We will investigate the quality of different models and simultaneously tune the hyperparameters. We will use functions to apply the model to the data and use different hyperparameters for each iteration. This will inform us of the best hyperparameters to use with the best model. We will use the fit() method for training, and the predict() method for testing. We will use the F1 score and the AUC_ROC to evaluate each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest Classifier <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 of the best model on the validation set (n_estimators = 7): 0.5795601552393274\n",
      "AUC-ROC score: 0.8142608949976078\n"
     ]
    }
   ],
   "source": [
    "# Developing a model with RandomForestClassifier\n",
    " \n",
    "best_score = 0\n",
    "best_est = 0\n",
    "for est in range(1, 11): # choose hyperparameter range\n",
    "    model = RandomForestClassifier(random_state=12345, n_estimators= est) \n",
    "    model.fit(features_upsampled, target_upsampled)\n",
    "    \n",
    "    predictions = model.predict(features_valid)\n",
    "    score = f1_score(target_valid, predictions)\n",
    "    if score > best_score:\n",
    "        best_score = score # save best f1 score on validation set\n",
    "        best_est = est # save number of estimators corresponding to best score\n",
    "        \n",
    "print(\"F1 of the best model on the validation set (n_estimators = {}): {}\".format(best_est, best_score))\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC-ROC score:',auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RandomForestClassifier (n_estimators = 7) had an F1 score of 0.58 and a AUC_ROC score of 0.81."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier Model <a class=\"anchor\" id=\"section_1_1\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 5\n",
      "F1 score of the best model on the validation set: 0.47585601404740996\n",
      "AUC-ROC score: 0.818801371441651\n"
     ]
    }
   ],
   "source": [
    "# Developing a model with DecisionTreeClassifier\n",
    " \n",
    "best_model = None\n",
    "best_result = 0\n",
    "\n",
    "for depth in range(1, 6):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth) \n",
    "    model.fit(features_upsampled, target_upsampled)\n",
    "    \n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    result = f1_score(target_valid, predicted_valid)\n",
    "    if result > best_result:  # save best f1 result on validation set\n",
    "        best_model = model\n",
    "        best_result = result\n",
    "        \n",
    "print(\"max_depth =\", depth)\n",
    "print(\"F1 score of the best model on the validation set:\", best_result)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC-ROC score:',auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1 score for the DecisionTreeClassifier Model (max_depth = 5) was 0.48 and the AUC-ROC was 0.82."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model <a class=\"anchor\" id=\"chapter1\"></a>\n",
    "\n",
    "The best model is the RandomForestClassifier model. Let's evaluate this model with the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Test <a class=\"anchor\" id=\"chapter1\"></a>\n",
    "\n",
    "### Assess the Model Using a Test Set <a class=\"anchor\" id=\"section_1_1\"></a>\n",
    "\n",
    "We will check quality of the RandomForestClassifier model we trained using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.5910224438902743\n",
      "AUC-ROC score: 0.8228006148280372\n"
     ]
    }
   ],
   "source": [
    "# Checking the quality of the RandomForestClassifier model using the test set.\n",
    " \n",
    "model = RandomForestClassifier(random_state=12345, n_estimators= 17) # set number of trees\n",
    "model.fit(features_upsampled, target_upsampled) # train model on training set\n",
    "    \n",
    "predicted_test = model.predict(features_test)\n",
    "F1 = f1_score(target_test, predicted_test)\n",
    "print('F1 score', F1)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC-ROC score:',auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RandomForestClassifier (n_estimators=17) had an F1 score of 0.59 and an AUC_ROC score of 0.82.  The n_estimators needed to be adjusted to 17 to improve the efficacy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Sanity Check <a class=\"anchor\" id=\"section_1_1\"></a>\n",
    "\n",
    "We will use a confusion Matrix to see if our model is really efficient at predicting the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.836"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_pred = model.predict(features_test)\n",
    "acc = model.score(features_test, target_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating a confusion matrix\n",
    "conf_matrix = metrics.confusion_matrix(target_test, target_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " # Plotting a confusion matrix\n",
    " \n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score: {0}'.format(acc)\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the confusion matrix, the model is predicting both classes and has a precision and recall rate that indicates the model performs better than random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Conclusion <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Beta Bank seeks to predict the likelihood of a customer leaving the bank soon. We used data on clients’ past behavior and termination of contracts with the bank to build a model that can predict whether or not a client will leave based on client information.\n",
    "\n",
    "The data contains 10000 records and 14 columns. All of the variables are numeric except 'surname', 'geography' and 'gender'. These are object types. Before encoding ‘gender’ and ‘geogrpahy’ to be numeric variables,  we dropped 'surname' from the dataframe. It would create too many columns and was unlikely to predict the target. We also dropped  'rownumber' and 'customerid' since they did not provide any useful information and would confuse the models.We converted all column names to lowercase to keep code clean and converted floats to integers. There were no duplicates. \n",
    "\n",
    "The only variable with missing values was 'tenure'. There were 909 missing values so dropping them would delete 9% of the data. The distribution of ‘tenure’ was pretty normal so we, therefore, filled in the missing values with the mean.\n",
    "\n",
    "We intially trained a model using LogisticRegression. Therefore, we used OHE to encode the categorical variables ‘gender’ and ‘geography’. We dropped ‘surname’ because it was unlikely to predict the target variable and would create too many columns. After OHE, the dataframe had 14 columns. We standardized the data. We assigned ‘exited’ as the target variable. We examined the balance of classes. There were 20% of ‘exited’ or “1” and 80% ‘did not exit’ or “0”, indicating a class imbalance. \n",
    "\n",
    "We split the data into a 3:1:1 ratio of 60% training, 20% validation, and 20% testing. We standardized the data. We trained a model using LogisticRegression. For the Logistic Regression Model F1 score was 0.30, which is relatively low, and the AUC_ROC score was 0.77. This was likely due to the class imbalance. \n",
    "\n",
    "We corrected the class imbalance using three approaches.Using a balanced parameter, the F1 score was 0.48, still low. The AUC_ROC was still 0.77. The F1 score of the LogisticRegression model after unsampling was 0.48 and the AUC_ROC was 0.77. The F1 score was 0.48 and the AUC_ROC was 0.77, after downsampling.\n",
    "\n",
    "We then developed different models using RandomForestClassifier and DecisionTreeClassifier. The RandomForestClassifier (n_estimators = 7) had an F1 score of 0.58 and a AUC_ROC score of 0.81.  The F1 score for the DecisionTreeClassifier Model (max_depth = 5) was 0.48 and the AUC-ROC was 0.82. The RandomForestClassifier has the best F1 score so we used this model and evaluated it with  the test set.\n",
    "\n",
    "The RandomForestClassifier (n_estimators=17) with the test set had an F1 score of 0.59 and an AUC_ROC score of 0.82.  The n_estimators needed to be adjusted to 17 to improve the efficacy of the model. We found an accuracy score of 0.84 on model.  To check the sanity of our model, we checked a confusion matrix and found that the model predicted the target variable more often than a random model, indicating the efficacy of our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "260.966px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
